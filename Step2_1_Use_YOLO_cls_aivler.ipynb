{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyurDtxqHT0o"
      },
      "source": [
        "# **Use YOLO-cls !**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WE6nWiH8-i9q"
      },
      "source": [
        "## 0.미션\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53bSTpVT-n_Y"
      },
      "source": [
        "### (1) 미션1\n",
        "여러분은 노트북에서 얼굴 인식 파일을 실행시키기 위해 **문제에 적합한** UltraLytics YOLO-cls 모델을 만들어야 합니다.\n",
        "\n",
        "그 전에 가지고 있는 데이터셋을 **학습에 적합한 형태**로 바꿔야 합니다.\n",
        "\n",
        "- 1) 데이터셋을 불러옵니다.\n",
        "    - 데이터셋은 2가지입니다. 본인의 얼굴 이미지 파일, 다른 사람의 얼굴 이미지 파일.\n",
        "- 2) 데이터셋을 전처리합니다.\n",
        "    - UltraLytics YOLO-cls 모델에서 요구하는 데이터셋 폴더의 구조가 있습니다.\n",
        "    - [UltraLytics YOLO-cls 모델의 데이터셋 구조 링크](https://docs.ultralytics.com/datasets/classify/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBjsZP8C-2Ra"
      },
      "source": [
        "### (2) 미션2\n",
        "데이터셋의 폴더 구조를 **학습에 적합한 형태**로 만들었다면, **사전 학습된 UltraLytics YOLO-cls 모델**에 Transfer Learning을 수행합니다.\n",
        "\n",
        "- 1) UltraLytics YOLO-cls 모델 선택\n",
        "    - 세부 모델로 n, s, m, l, x가 있습니다. n가 가장 빠르고, x가 가장 연산량이 많습니다.\n",
        "    - [UltraLytics YOLO-cls 모델 링크](https://docs.ultralytics.com/tasks/classify/)\n",
        "- 2) 선택한 UltraLytics YOLO-cls 모델로 학습을 진행합니다.\n",
        "    - [UltraLytics YOLO 학습 명령어 링크](https://docs.ultralytics.com/modes/train/#train-settings)\n",
        "- 3) 학습이 완료되면 추론을 진행합니다.\n",
        "    - [UltraLytics YOLO 추론 명령어 링크](https://docs.ultralytics.com/modes/predict/#inference-arguments)\n",
        "- 4) 해당 UltraLytics YOLO-cls 모델을 **반드시** 저장합니다.\n",
        "    - 모델을 **반드시** 저장하세요.\n",
        "    - .pt 형태로 Colab에 저장이 될 것입니다. 해당 파일을 **로컬에 다운로드** 하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkDv7UfdYOgg"
      },
      "source": [
        "## 1.환경설정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIxbiQ8wYOcy"
      },
      "source": [
        "* 세부 요구사항\n",
        "    - 경로 설정 : 구글콜랩\n",
        "        * 구글 드라이브 바로 밑에 project4 폴더를 만드세요.\n",
        "        * 데이터 파일을 복사해 넣습니다.\n",
        "        * 필요하다고 판단되는 라이브러리를 추가하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIjpXC-xYHh3"
      },
      "source": [
        "### (1) 경로 설정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6qgvZMSYcoX"
      },
      "source": [
        "* 구글 드라이브 연결"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imfft4dGGJ2E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe75777b-d091-4585-a303-7044921e6f98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPngJ_nwZPRC"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/project4'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNEKwf_LY0JB"
      },
      "source": [
        "### (2) 라이브러리 설치 및 불러오기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPwDW6e_Y0Fa"
      },
      "source": [
        "* 라이브러리 로딩"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4dS7tW-Zwrx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c2ea804-8133-4579-927e-28d17077cda2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.3.24)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (10.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.9)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "## colab에서 세션 재시작을 요구하는 팝업이 뜨면 재시작 누르세요.\n",
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eg0gCl9Yatak"
      },
      "source": [
        "## 2.미션1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPvTHwTmbKR5"
      },
      "source": [
        "여러분은 노트북에서 얼굴 인식 파일을 실행시키기 위해 **문제에 적합한** UltraLytics YOLO-cls 모델을 만들어야 합니다.\n",
        "\n",
        "그 전에 가지고 있는 데이터셋을 **학습에 적합한 형태**로 바꿔야 합니다.\n",
        "\n",
        "- 1) 데이터셋을 불러옵니다.\n",
        "    - 데이터셋은 2가지입니다. 본인의 얼굴 이미지 파일, 다른 사람의 얼굴 이미지 파일.\n",
        "- 2) 데이터셋을 전처리합니다.\n",
        "    - UltraLytics YOLO-cls 모델에서 요구하는 데이터셋 폴더의 구조가 있습니다.\n",
        "    - [UltraLytics YOLO-cls 모델의 데이터셋 구조 링크](https://docs.ultralytics.com/datasets/classify/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rXSONrsatd5"
      },
      "source": [
        "### (1) 데이터셋 불러오기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXLqxwNaathI"
      },
      "source": [
        "* **세부 요구사항**\n",
        "    - 데이터셋을 불러옵니다.\n",
        "        - 데이터셋은 두 개의 압축 파일이어야 합니다.\n",
        "            1. lfw-deepfunneled.zip : Labeled Faces in the Wild 데이터셋\n",
        "                - 압축 파일을 로컬에 다운로드 받아서 **어떤 구조**인지 확인하세요.\n",
        "            2. 여러분의 얼굴 이미지 데이터셋\n",
        "                - 여러분의 얼굴 이미지가 담긴 **압축 파일**을 **Google Drive에 업로드** 하기를 권장합니다.\n",
        "                    - 이미지 파일 하나하나 업로드 하면 시간이 오래 걸립니다.\n",
        "    - 데이터셋 압축 파일을 **Colab에 폴더를 생성한 후 해제**하세요.\n",
        "        - 데이터셋 폴더를 **본인 얼굴 폴더, LFW 폴더로 나누어** 생성하는 것을 권장합니다.\n",
        "        - 만일 두 압축 파일을 하나의 폴더에 모두 해제하면 전처리가 더 까다로워질 것입니다.\n",
        "    - 예시 코드에서 사용한 라이브러리\n",
        "        - os, zipfile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OntGw5H-C3q"
      },
      "source": [
        "#### 1) 본인 얼굴 이미지 데이터셋 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile"
      ],
      "metadata": {
        "id": "-KsjKILk5ByM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFq5L4aAeQHr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "99979aae-c9c3-45fa-dbdf-826bb4116487"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/project4/Datasets/Keras/my_face_MJ_11000.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "data_myFace = os.path.join(path, 'Datasets/Keras/my_face_MJ_11000.zip')\n",
        "data_myFace"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Colab에 생성할 본인 얼굴 폴더 경로\n",
        "extract_folder = '/content/my_face'\n",
        "\n",
        "## 위의 경로에 폴더가 없을 때 생성\n",
        "if not os.path.exists(extract_folder) :\n",
        "    os.makedirs(extract_folder)\n",
        "\n",
        "## 위의 경로에 압축을 해제\n",
        "with zipfile.ZipFile(data_myFace, 'r') as zip_ref :\n",
        "    file_list = zip_ref.namelist()\n",
        "\n",
        "    for f in file_list :\n",
        "        if not f.endswith('/') and f.lower().endswith('.jpg') :\n",
        "            file_name = os.path.basename(f)\n",
        "\n",
        "            if not file_name.startswith('._') :\n",
        "                d_path = os.path.join(extract_folder, file_name)\n",
        "\n",
        "                with zip_ref.open(f) as source, open(d_path, 'wb') as target :\n",
        "                    target.write(source.read())"
      ],
      "metadata": {
        "id": "SK-U-s-U0Wn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 생성된 본인 얼굴 이미지 데이터 폴더 안의 이미지 수\n",
        "len(os.listdir(extract_folder) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_I97Fos0XOJ",
        "outputId": "b6557744-6254-4f4a-fe2c-dba0913ead36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11527"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCDldok5ySsg"
      },
      "source": [
        "#### 2) 다른 얼굴 이미지 데이터셋 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rITP9F5qeQ5K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c1bde2db-38c0-4aa9-aecb-ad46c2bcf38a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/project4/Datasets/Keras/lfw-deepfunneled.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "data_other = path + '/Datasets/Keras/lfw-deepfunneled.zip'\n",
        "data_other"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Colab에 생성할 다른 얼굴 폴더 경로\n",
        "extract_folder = '/content/other_face'\n",
        "\n",
        "## 위의 경로에 폴더가 없을 때 생성\n",
        "if not os.path.exists(extract_folder) :\n",
        "    os.makedirs(extract_folder)\n",
        "\n",
        "## 위의 경로에 압축을 해제\n",
        "with zipfile.ZipFile(data_other, 'r') as zip_ref :\n",
        "    file_list = zip_ref.namelist()\n",
        "\n",
        "    for f in file_list :\n",
        "        if not f.endswith('/') and f.lower().endswith('.jpg') :\n",
        "            file_name = os.path.basename(f)\n",
        "\n",
        "            if not file_name.startswith('._') :\n",
        "                d_path = os.path.join(extract_folder, file_name)\n",
        "\n",
        "                with zip_ref.open(f) as source, open(d_path, 'wb') as target :\n",
        "                    target.write(source.read())"
      ],
      "metadata": {
        "id": "h-c75c5B0bNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 생성된 다른 사람 얼굴 이미지 데이터 폴더 안의 이미지 수\n",
        "len(os.listdir(extract_folder) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rA8j6ke00bpt",
        "outputId": "10018a35-037d-4f70-f1d9-92452d2245d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13233"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-TovD9FLCCL"
      },
      "source": [
        "### (2) 데이터셋 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJPBtHv8LCCL"
      },
      "source": [
        "* **세부 요구사항**\n",
        "    - 데이터셋을 전처리 합니다.\n",
        "        - YOLO-cls 모델이 요구하는 폴더 구조를 만듭니다.\n",
        "            1. Datasets라는 폴더를 생성합니다.\n",
        "            2. Training set, Validation set, Test set(선택 사항) 각 데이터셋이 들어갈 폴더를 생성합니다.\n",
        "            3. 각 데이터셋 폴더에 분류할 클래스의 이름을 가진 폴더를 생성합니다.\n",
        "        - 폴더 구조에 맞게 데이터를 분배합니다.\n",
        "    - 예시 코드에서 사용한 라이브러리\n",
        "        - os, glob, random, shutil, numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_MF4zCRie5X"
      },
      "source": [
        "#### 1) 모델이 요하는 구조의 폴더 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTzgG1M1eR-A"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import random\n",
        "import shutil\n",
        "import numpy as np\n",
        "\n",
        "from keras.utils import load_img, img_to_array\n",
        "from keras.utils import image_dataset_from_directory"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## image_dataset_from_directory를 사용하기 위해 Colab에 폴더 생성\n",
        "\n",
        "base_dir = '/content/datas'\n",
        "\n",
        "if not os.path.exists(base_dir) :\n",
        "    os.makedirs(base_dir)\n",
        "\n",
        "tr_data = '/content/datas/train'\n",
        "val_data = '/content/datas/val'\n",
        "te_data = '/content/datas/test'\n",
        "\n",
        "## 폴더가 존재하지 않을 때 폴더를 생성\n",
        "if not os.path.exists(tr_data) :\n",
        "    os.makedirs(tr_data)\n",
        "\n",
        "if not os.path.exists(te_data) :\n",
        "    os.makedirs(te_data)\n",
        "\n",
        "if not os.path.exists(val_data) :\n",
        "    os.makedirs(val_data)\n",
        "\n",
        "## 폴더 생성 확인\n",
        "print(os.path.exists(tr_data) )\n",
        "print(os.path.exists(te_data) )\n",
        "print(os.path.exists(val_data) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_llvUkT0-gDy",
        "outputId": "2d2c9cbc-4f37-43f0-d188-4a67171db4b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZPds1GraeJ3"
      },
      "source": [
        "#### 2) 각 폴더에 이미지 데이터 옮기기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfVQOMf8eTkb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf906c54-2e0b-4464-c9e4-7e2e4e6ca51e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "## Keras의 image_dataset_from_directory를 사용하기 위해 Colab에 하위 폴더 생성\n",
        "\n",
        "## 생성될 폴더에 대한 하위 폴더 생성\n",
        "class_names = ['my', 'other']\n",
        "\n",
        "for cn in class_names :\n",
        "    temp = os.path.join(tr_data, cn)\n",
        "\n",
        "    if not os.path.exists( temp ) :\n",
        "        os.makedirs(temp)\n",
        "\n",
        "    ## 폴더 생성 확인\n",
        "    print(os.path.exists(temp))\n",
        "\n",
        "for cn in class_names :\n",
        "    temp = os.path.join(te_data, cn)\n",
        "\n",
        "    if not os.path.exists( temp ) :\n",
        "        os.makedirs(temp)\n",
        "\n",
        "    ## 폴더 생성 확인\n",
        "    print(os.path.exists(temp))\n",
        "\n",
        "for cn in class_names :\n",
        "    temp = os.path.join(val_data, cn)\n",
        "\n",
        "    if not os.path.exists( temp ) :\n",
        "        os.makedirs(temp)\n",
        "\n",
        "    ## 폴더 생성 확인\n",
        "    print(os.path.exists(temp))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 본인 얼굴 데이터가 있는 폴더 경로의 파일 전체를 정렬하여 리스트화\n",
        "img_list_my = sorted(glob.glob('/content/my_face/*',))\n",
        "\n",
        "## 다른 얼굴 데이터가 있는 폴더 경로의 파일 전체를 정렬하여 리스트화\n",
        "img_list_other = sorted(glob.glob('/content/other_face/*'))\n",
        "\n",
        "## 이미지 갯수 확인\n",
        "len(img_list_my), len(img_list_other)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KS0EOHD1-7sK",
        "outputId": "1f4c065c-7053-442a-a5fb-08d851a2fef2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11527, 13233)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 얼굴 데이터를 Training set, Test set으로 분할하기 위한 사전 작업\n",
        "## 분할 재현성을 위한 난수 고정\n",
        "random.seed(2024)\n",
        "random.shuffle(img_list_my)\n",
        "random.shuffle(img_list_other)\n",
        "\n",
        "img_list_my[:5], img_list_other[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wA9W295Q-9tb",
        "outputId": "4e2c3a63-cef6-41a7-d28d-c9301d6ea927"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['/content/my_face/face_11181.jpg',\n",
              "  '/content/my_face/face_10007.jpg',\n",
              "  '/content/my_face/face_15538.jpg',\n",
              "  '/content/my_face/face_13516.jpg',\n",
              "  '/content/my_face/face_12908.jpg'],\n",
              " ['/content/other_face/Pat_Riley_0001.jpg',\n",
              "  '/content/other_face/Choi_Sung-hong_0001.jpg',\n",
              "  '/content/other_face/Russell_Simmons_0003.jpg',\n",
              "  '/content/other_face/Richard_Gere_0003.jpg',\n",
              "  '/content/other_face/Debbie_Reynolds_0003.jpg'])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 나의 얼굴 파일 리스트와 다른 얼굴 파일 리스트에 대한 반복문\n",
        "for i_l in [img_list_my, img_list_other] :\n",
        "    ## 리스트의 길이 체크\n",
        "    list_len = len(i_l)\n",
        "    # list_len = 13000  ## 예시 파일의 이미지 갯수가 맞지 않아서 11000개까지만 사용\n",
        "    ## 데이터 분할을 위한 인덱스 설정\n",
        "    split_idx_1 = int(list_len * 0.7)\n",
        "    split_idx_2 = int(list_len * 0.9)\n",
        "    print(split_idx_1, split_idx_2, list_len)\n",
        "\n",
        "    ## 인덱스를 이용해 상위 리스트를 Training set, Test set 2가지로 세분화\n",
        "    list_tr = i_l[ : split_idx_1]\n",
        "    list_val = i_l[split_idx_1 : split_idx_2]\n",
        "    list_te = i_l[split_idx_2 : list_len]\n",
        "\n",
        "    ## 현재 리스트가 나의 얼굴 파일 리스트와 같다면\n",
        "    if i_l == img_list_my :\n",
        "        ## \"나의 얼굴 파일 리스트\"의 파일을 Training set 폴더 안의 \"나의 얼굴 폴더\"로 복사\n",
        "        ## 이동이 잘못 되었을 경우를 생각하여 복사로 진행\n",
        "        for file_path in list_tr :\n",
        "            f_name = file_path.split('/')\n",
        "            shutil.copy(src=file_path,\n",
        "                        dst=tr_data+'/my/'+f_name[-1]\n",
        "                        )\n",
        "            # print(f'파일 이동 완료 : {f_name[-1]}')\n",
        "\n",
        "        ## \"나의 얼굴 파일 리스트\"의 파일을 Val set 폴더 안의 \"나의 얼굴 폴더\"로 복사\n",
        "        ## 이동이 잘못 되었을 경우를 생각하여 복사로 진행\n",
        "        for file_path in list_val :\n",
        "            f_name = file_path.split('/')\n",
        "            shutil.copy(src=file_path,\n",
        "                        dst=val_data+'/my/'+f_name[-1]\n",
        "                        )\n",
        "            # print(f'파일 이동 완료 : {f_name[-1]}')\n",
        "\n",
        "        ## \"나의 얼굴 파일 리스트\"의 파일을 Test set 폴더 안의 \"나의 얼굴 폴더\"로 복사\n",
        "        ## 이동이 잘못 되었을 경우를 생각하여 복사로 진행\n",
        "        for file_path in list_te :\n",
        "            f_name = file_path.split('/')\n",
        "            shutil.copy(src=file_path,\n",
        "                        dst=te_data+'/my/'+f_name[-1]\n",
        "                        )\n",
        "            # print(f'파일 이동 완료 : {f_name[-1]}')\n",
        "\n",
        "    ## 현재 리스트가 \"나의 얼굴 파일 리스트\"가 아니라면 (즉, \"다른 사람 얼굴 파일 리스트\"라면)\n",
        "    else :\n",
        "        ## \"다른 사람 얼굴 파일 리스트\"의 파일을 Training set 폴더 안의 \"다른 사람 얼굴 폴더\"로 복사\n",
        "        ## 이동이 잘못 되었을 경우를 생각하여 복사로 진행\n",
        "        for file_path in list_tr :\n",
        "            f_name = file_path.split('/')\n",
        "            shutil.copy(src=file_path,\n",
        "                        dst=tr_data+'/other/'+f_name[-1],\n",
        "                        )\n",
        "            # print(f'파일 이동 완료 : {f_name[-1]}')\n",
        "\n",
        "\n",
        "        ## \"다른 사람 얼굴 파일 리스트\"의 파일을 val set 폴더 안의 \"다른 사람 얼굴 폴더\"로 복사\n",
        "        ## 이동이 잘못 되었을 경우를 생각하여 복사로 진행\n",
        "        for file_path in list_val :\n",
        "            f_name = file_path.split('/')\n",
        "            shutil.copy(src=file_path,\n",
        "                        dst=val_data+'/other/'+f_name[-1],\n",
        "                        )\n",
        "            # print(f'파일 이동 완료 : {f_name[-1]}')\n",
        "\n",
        "        ## \"다른 사람 얼굴 파일 리스트\"의 파일을 Test set 폴더 안의 \"다른 사람 얼굴 폴더\"로 복사\n",
        "        ## 이동이 잘못 되었을 경우를 생각하여 복사로 진행\n",
        "        for file_path in list_te :\n",
        "            f_name = file_path.split('/')\n",
        "            shutil.copy(src=file_path,\n",
        "                        dst=te_data+'/other/'+f_name[-1]\n",
        "                        )\n",
        "            # print(f'파일 이동 완료 : {f_name[-1]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmTTgKfE_An3",
        "outputId": "0b1150c8-6453-44f0-ae63-f2ed10156f48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8068 10374 11527\n",
            "9263 11909 13233\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Training data의 my_face 이미지 수 : ', len(os.listdir('/content/datas/train/my')))\n",
        "print('Training data의 other_face 이미지 수 : ', len(os.listdir('/content/datas/train/other')))\n",
        "\n",
        "print('Val data의 my_face 이미지 수 : ', len(os.listdir('/content/datas/val/my')))\n",
        "print('Val data의 other_face 이미지 수 : ', len(os.listdir('/content/datas/val/other')))\n",
        "\n",
        "print('Test data의 my_face 이미지 수 : ', len(os.listdir('/content/datas/test/my')))\n",
        "print('Test data의 other_face 이미지 수 : ', len(os.listdir('/content/datas/test/other')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPQwzgYd_ZLZ",
        "outputId": "53a9d93f-3078-440d-c762-6758dae05105"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data의 my_face 이미지 수 :  8068\n",
            "Training data의 other_face 이미지 수 :  12023\n",
            "Val data의 my_face 이미지 수 :  2306\n",
            "Val data의 other_face 이미지 수 :  4736\n",
            "Test data의 my_face 이미지 수 :  1153\n",
            "Test data의 other_face 이미지 수 :  2529\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Training set 데이터 폴더를 데이터셋화\n",
        "## 이 과정에서 Validation set도 생성\n",
        "tr_idfd = image_dataset_from_directory(tr_data,                    ## Training 폴더 경로\n",
        "                                       class_names=['other','my'], ## 클래스 순서 지정\n",
        "                                       batch_size=32,              ## 이미지 덩어리 단위\n",
        "                                       image_size=(160,160),       ## 이미지 리사이즈\n",
        "                                       shuffle=True,               ## 섞어야 올바르게 분할됨\n",
        "                                       seed=2024,                  ## 재현성\n",
        "                                       )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHbHz1wN_cYx",
        "outputId": "c97842fc-cef0-46d5-d176-0a2622f9ba45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20091 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Val set 데이터 폴더를 데이터셋화\n",
        "val_idfd = image_dataset_from_directory(val_data,                  ## Val 폴더 경로\n",
        "                                       class_names=['other','my'], ## 클래스 순서 지정\n",
        "                                       batch_size=32,              ## 이미지 덩어리 단위\n",
        "                                       image_size=(160,160),       ## 이미지 리사이즈\n",
        "                                       shuffle=True,               ## 섞어야 올바르게 분할됨\n",
        "                                       seed=2024                   ## 재현성\n",
        "                                       )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FL4pEimGo80",
        "outputId": "585a6d23-8a8b-4d0f-d176-7791283ce21e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7042 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Test set 데이터 폴더를 데이터셋화\n",
        "te_idfd = image_dataset_from_directory(te_data,                    ## Test 폴더 경로\n",
        "                                       class_names=['other','my'], ## 클래스 순서 지정\n",
        "                                       batch_size=32,              ## 이미지 덩어리 단위\n",
        "                                       image_size=(160,160),       ## 이미지 리사이즈\n",
        "                                       shuffle=True,               ## 섞어야 올바르게 분할됨\n",
        "                                       seed=2024                   ## 재현성\n",
        "                                       )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzxUxVCQ_ee_",
        "outputId": "02d935d0-f751-4198-a82d-6b1632c87bca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3682 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rescale(image, label) :\n",
        "    image = image / 255\n",
        "    return image, label"
      ],
      "metadata": {
        "id": "NIxHEmwP_g60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr_idfd_rescale = tr_idfd.map(rescale)\n",
        "val_idfd_rescale = val_idfd.map(rescale)\n",
        "te_idfd_rescale = te_idfd.map(rescale)"
      ],
      "metadata": {
        "id": "40uaeboC_i-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w59u5Dtnrh5h"
      },
      "source": [
        "## 3.미션2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHu91EoOrh2Q"
      },
      "source": [
        "데이터셋의 폴더 구조를 **학습에 적합한 형태**로 만들었다면, **사전 학습된 UltraLytics YOLO-cls 모델**에 Transfer Learning을 수행합니다.\n",
        "\n",
        "- 1) UltraLytics YOLO-cls 모델 선택\n",
        "    - 세부 모델로 n, s, m, l, x가 있습니다. n가 가장 빠르고, x가 가장 연산량이 많습니다.\n",
        "    - [UltraLytics YOLO-cls 모델 링크](https://docs.ultralytics.com/tasks/classify/)\n",
        "- 2) 선택한 UltraLytics YOLO-cls 모델로 학습을 진행합니다.\n",
        "    - [UltraLytics YOLO 학습 명령어 링크](https://docs.ultralytics.com/modes/train/#train-settings)\n",
        "- 3) 학습이 완료되면 추론을 진행합니다.\n",
        "    - [UltraLytics YOLO 추론 명령어 링크](https://docs.ultralytics.com/modes/predict/#inference-arguments)\n",
        "- 4) 해당 UltraLytics YOLO-cls 모델을 **반드시** 저장합니다.\n",
        "    - 모델을 **반드시** 저장하세요.\n",
        "    - .pt 형태로 Colab에 저장이 될 것입니다. 해당 파일을 **로컬에 다운로드** 하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AygPItZba0TI"
      },
      "source": [
        "#### (1) UltraLytics YOLO-cls 모델 선택"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7zOy5GfbMTR"
      },
      "source": [
        "* **세부 요구사항**\n",
        "    - 세부 모델로 n, s, m, l, x가 있습니다. n가 가장 빠르고, x가 가장 연산량이 많습니다.\n",
        "    - [UltraLytics YOLO-cls 모델 링크](https://docs.ultralytics.com/tasks/classify/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULEjDkdUGhCz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12a1a985-47b2-4b00-80cd-43666e09d5c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.3.24)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (10.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.9)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "LJQqtBLYOV9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7rqg7bda6Uz"
      },
      "source": [
        "#### (2) UltraLytics YOLO-cls 모델 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48UKFtS6bc9b"
      },
      "source": [
        "* **세부 요구사항**\n",
        "    - 선택한 UltraLytics YOLO-cls 모델로 학습을 진행합니다.\n",
        "    - [UltraLytics YOLO 학습 명령어 링크](https://docs.ultralytics.com/modes/train/#train-settings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "891Qn60yGhCz"
      },
      "outputs": [],
      "source": [
        "model = YOLO(model='yolo11x-cls.pt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.train(data='/content/datas', epochs=5, imgsz=224, batch=32, seed=2024)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        },
        "id": "MzNS9iGEOoFT",
        "outputId": "25cff474-0d09-4e6f-a8d0-1f1c11172dae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.24 🚀 Python-3.10.12 torch-2.5.0+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolo11x-cls.pt, data=/content/datas, epochs=5, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train22, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=2024, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/train22\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/datas/train... found 20091 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/datas/val... found 7042 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /content/datas/test... found 3682 images in 2 classes ✅ \n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      2784  ultralytics.nn.modules.conv.Conv             [3, 96, 3, 2]                 \n",
            "  1                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  2                  -1  2    389760  ultralytics.nn.modules.block.C3k2            [192, 384, 2, True, 0.25]     \n",
            "  3                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
            "  4                  -1  2   1553664  ultralytics.nn.modules.block.C3k2            [384, 768, 2, True, 0.25]     \n",
            "  5                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
            "  6                  -1  2   5022720  ultralytics.nn.modules.block.C3k2            [768, 768, 2, True]           \n",
            "  7                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
            "  8                  -1  2   5022720  ultralytics.nn.modules.block.C3k2            [768, 768, 2, True]           \n",
            "  9                  -1  2   3264768  ultralytics.nn.modules.block.C2PSA           [768, 768, 2]                 \n",
            " 10                  -1  1    988162  ultralytics.nn.modules.head.Classify         [768, 2]                      \n",
            "YOLO11x-cls summary: 309 layers, 28,358,626 parameters, 28,358,626 gradients, 111.0 GFLOPs\n",
            "Transferred 494/494 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/classify/train22', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datas/train... 20091 images, 0 corrupt: 100%|██████████| 20091/20091 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datas/val... 7042 images, 0 corrupt: 100%|██████████| 7042/7042 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 82 weight(decay=0.0), 83 weight(decay=0.0005), 83 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 224 train, 224 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/classify/train22\u001b[0m\n",
            "Starting training for 5 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/5      3.44G  0.0002085         32        224:  28%|██▊       | 173/628 [00:18<00:48,  9.47it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-c34a1c485ecc>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/datas'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgsz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m  \u001b[0;31m# attach optional HUB session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m         \u001b[0;31m# Update model and cfg after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0;31m# Backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 \u001b[0;31m# Optimize - https://pytorch.org/docs/master/notes/amp_examples.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsxBhoAubn2u"
      },
      "source": [
        "#### (3) UltraLytics YOLO-cls 추론"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPtTHcnbbn2u"
      },
      "source": [
        "* **세부 요구사항**\n",
        "    - 학습이 완료되면 추론을 진행합니다.\n",
        "    - [UltraLytics YOLO 추론 명령어 링크](https://docs.ultralytics.com/modes/predict/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ffQ725eGhC0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ytKJsOUGhC0"
      },
      "source": [
        "#### (4) UltraLytics YOLO-cls 모델 저장"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkC4WP-8cA7g"
      },
      "source": [
        "* **세부 요구사항**\n",
        "    - 모델을 **반드시** 저장하세요.\n",
        "    - .pt 형태로 Colab에 저장이 될 것입니다. 해당 파일을 **로컬에 다운로드** 하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMLUGduLGhC0"
      },
      "outputs": [],
      "source": [
        "# 학습된 모델 저장 경로\n",
        "model_path = \"./yolo11x-v1.pt\"\n",
        "model.save(model_path)\n",
        "print(f\"모델이 {model_path}에 저장되었습니다.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}